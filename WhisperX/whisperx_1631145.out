Requirement already satisfied: pip in ./whisper_env/lib/python3.11/site-packages (24.0)
Collecting pip
  Using cached pip-25.2-py3-none-any.whl.metadata (4.7 kB)
Using cached pip-25.2-py3-none-any.whl (1.8 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 24.0
    Uninstalling pip-24.0:
      Successfully uninstalled pip-24.0
Successfully installed pip-25.2
Collecting whisperx
  Downloading whisperx-3.7.4-py3-none-any.whl.metadata (16 kB)
Collecting yt-dlp
  Using cached yt_dlp-2025.10.22-py3-none-any.whl.metadata (176 kB)
Collecting torch
  Downloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)
Collecting ctranslate2>=4.5.0 (from whisperx)
  Using cached ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Collecting faster-whisper>=1.1.1 (from whisperx)
  Using cached faster_whisper-1.2.0-py3-none-any.whl.metadata (16 kB)
Collecting nltk>=3.9.1 (from whisperx)
  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)
Collecting numpy<2.1.0,>=2.0.2 (from whisperx)
  Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)
Collecting pandas<2.3.0,>=2.2.3 (from whisperx)
  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)
Collecting av<16.0.0 (from whisperx)
  Using cached av-15.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)
Collecting pyannote-audio<4.0.0,>=3.3.2 (from whisperx)
  Using cached pyannote_audio-3.4.0-py2.py3-none-any.whl.metadata (11 kB)
Collecting torch
  Using cached torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)
Collecting torchaudio~=2.8.0 (from whisperx)
  Using cached torchaudio-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.2 kB)
Collecting transformers>=4.48.0 (from whisperx)
  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)
Collecting triton>=3.3.0 (from whisperx)
  Downloading triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)
Collecting filelock (from torch)
  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)
Collecting typing-extensions>=4.10.0 (from torch)
  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting sympy>=1.13.3 (from torch)
  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch)
  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch)
  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch)
  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)
Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)
  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)
  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)
  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)
  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)
  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)
  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-curand-cu12==10.3.9.90 (from torch)
  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)
  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)
  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)
  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)
Collecting nvidia-nccl-cu12==2.27.3 (from torch)
  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)
Collecting nvidia-nvtx-cu12==12.8.90 (from torch)
  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)
  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)
  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
Collecting triton>=3.3.0 (from whisperx)
  Using cached triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)
Requirement already satisfied: setuptools>=40.8.0 in ./whisper_env/lib/python3.11/site-packages (from triton>=3.3.0->whisperx) (65.5.0)
Collecting python-dateutil>=2.8.2 (from pandas<2.3.0,>=2.2.3->whisperx)
  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.2.3->whisperx)
  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)
Collecting tzdata>=2022.7 (from pandas<2.3.0,>=2.2.3->whisperx)
  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)
Collecting asteroid-filterbanks>=0.4 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)
Collecting einops>=0.6.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)
Collecting huggingface_hub>=0.13.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)
Collecting lightning>=2.0.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached lightning-2.5.5-py3-none-any.whl.metadata (39 kB)
Collecting omegaconf<3.0,>=2.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)
Collecting pyannote.core<6.0,>=5.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)
Collecting pyannote.database<6.0,>=5.0.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)
Collecting pyannote.metrics<4.0,>=3.2 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)
Collecting pyannote.pipeline<4.0,>=3.0.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)
Collecting pytorch_metric_learning>=2.1.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pytorch_metric_learning-2.9.0-py3-none-any.whl.metadata (18 kB)
Collecting rich>=12.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)
Collecting semver>=3.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)
Collecting soundfile>=0.12.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)
Collecting speechbrain>=1.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)
Collecting tensorboardX>=2.6 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)
Collecting torch_audiomentations>=0.11.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)
Collecting torchmetrics>=0.11.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)
Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0,>=2.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl
Collecting PyYAML>=5.1.0 (from omegaconf<3.0,>=2.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)
Collecting sortedcontainers>=2.0.4 (from pyannote.core<6.0,>=5.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)
Collecting scipy>=1.1 (from pyannote.core<6.0,>=5.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)
Collecting typer>=0.12.1 (from pyannote.database<6.0,>=5.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached typer-0.20.0-py3-none-any.whl.metadata (16 kB)
Collecting scikit-learn>=0.17.1 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)
Collecting docopt>=0.6.2 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached docopt-0.6.2-py2.py3-none-any.whl
Collecting tabulate>=0.7.7 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)
Collecting matplotlib>=2.0.0 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)
Collecting optuna>=3.1 (from pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached optuna-4.5.0-py3-none-any.whl.metadata (17 kB)
Collecting tqdm>=4.29.1 (from pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
Collecting tokenizers<1,>=0.13 (from faster-whisper>=1.1.1->whisperx)
  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)
Collecting onnxruntime<2,>=1.14 (from faster-whisper>=1.1.1->whisperx)
  Using cached onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)
Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx)
  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)
Collecting flatbuffers (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx)
  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)
Collecting packaging (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx)
  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
Collecting protobuf (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx)
  Using cached protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)
Collecting requests (from huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)
Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)
Collecting pytorch-lightning (from lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)
Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Downloading aiohttp-3.13.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)
Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)
Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)
Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)
Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)
Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Downloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)
Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)
Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting contourpy>=1.0.1 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)
Collecting cycler>=0.10 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
Collecting fonttools>=4.22.0 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)
Collecting kiwisolver>=1.3.1 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)
Collecting pillow>=8 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)
Collecting pyparsing>=3 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)
Collecting click (from nltk>=3.9.1->whisperx)
  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)
Collecting joblib (from nltk>=3.9.1->whisperx)
  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)
Collecting regex>=2021.8.3 (from nltk>=3.9.1->whisperx)
  Downloading regex-2025.10.23-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)
Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached alembic-1.17.0-py3-none-any.whl.metadata (7.2 kB)
Collecting colorlog (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)
Collecting sqlalchemy>=1.4.2 (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached sqlalchemy-2.0.44-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)
Collecting Mako (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)
Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.2.3->whisperx)
  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting markdown-it-py>=2.2.0 (from rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)
Collecting pygments<3.0.0,>=2.13.0 (from rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)
Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)
Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.17.1->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
Collecting cffi>=1.0 (from soundfile>=0.12.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)
Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)
Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)
Collecting sentencepiece (from speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)
Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)
  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Collecting julius<0.3,>=0.2.3 (from torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached julius-0.2.7-py3-none-any.whl
Collecting torch-pitch-shift>=1.2.2 (from torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)
Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached primePy-1.3-py3-none-any.whl.metadata (4.8 kB)
Collecting safetensors>=0.4.3 (from transformers>=4.48.0->whisperx)
  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)
Collecting shellingham>=1.3.0 (from typer>=0.12.1->pyannote.database<6.0,>=5.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)
Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx)
  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)
Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)
Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached ruamel.yaml.clib-0.2.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch)
  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)
Collecting charset_normalizer<4,>=2 (from requests->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)
Collecting urllib3<3,>=1.21.1 (from requests->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)
Downloading whisperx-3.7.4-py3-none-any.whl (16.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.5/16.5 MB 53.2 MB/s  0:00:00
Using cached torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)
Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)
Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)
Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)
Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)
Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)
Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)
Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)
Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)
Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)
Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)
Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)
Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)
Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)
Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)
Using cached triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)
Using cached av-15.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.6 MB)
Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)
Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)
Using cached pyannote_audio-3.4.0-py2.py3-none-any.whl (897 kB)
Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)
Using cached pyannote.core-5.0.0-py3-none-any.whl (58 kB)
Using cached pyannote.database-5.1.3-py3-none-any.whl (48 kB)
Using cached pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)
Using cached pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)
Using cached torchaudio-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.0 MB)
Using cached yt_dlp-2025.10.22-py3-none-any.whl (3.2 MB)
Using cached asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)
Using cached ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)
Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 806.6/806.6 kB 33.3 MB/s  0:00:00
Using cached einops-0.8.1-py3-none-any.whl (64 kB)
Using cached faster_whisper-1.2.0-py3-none-any.whl (1.1 MB)
Using cached onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)
Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 566.1/566.1 kB 20.4 MB/s  0:00:00
Using cached hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)
Downloading filelock-3.20.0-py3-none-any.whl (16 kB)
Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)
Using cached lightning-2.5.5-py3-none-any.whl (828 kB)
Using cached lightning_utilities-0.15.2-py3-none-any.whl (29 kB)
Using cached packaging-25.0-py3-none-any.whl (66 kB)
Using cached torchmetrics-1.8.2-py3-none-any.whl (983 kB)
Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)
Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Downloading aiohttp-3.13.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 43.2 MB/s  0:00:00
Downloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)
Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (365 kB)
Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)
Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)
Downloading attrs-25.4.0-py3-none-any.whl (67 kB)
Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (231 kB)
Downloading idna-3.11-py3-none-any.whl (71 kB)
Using cached matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)
Using cached contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)
Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)
Using cached fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)
Using cached kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)
Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)
Using cached optuna-4.5.0-py3-none-any.whl (400 kB)
Using cached alembic-1.17.0-py3-none-any.whl (247 kB)
Using cached pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)
Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (210 kB)
Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)
Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Using cached pytorch_metric_learning-2.9.0-py3-none-any.whl (127 kB)
Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)
Downloading regex-2025.10.23-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 800.3/800.3 kB 36.2 MB/s  0:00:00
Using cached rich-14.2.0-py3-none-any.whl (243 kB)
Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)
Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)
Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)
Using cached scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)
Using cached joblib-1.5.2-py3-none-any.whl (308 kB)
Using cached scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)
Using cached semver-3.0.4-py3-none-any.whl (17 kB)
Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)
Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)
Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)
Using cached cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (215 kB)
Using cached speechbrain-1.0.3-py3-none-any.whl (864 kB)
Using cached sqlalchemy-2.0.44-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
Using cached greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (587 kB)
Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)
Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)
Using cached tensorboardx-2.6.4-py3-none-any.whl (87 kB)
Using cached protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)
Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
Using cached torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)
Using cached torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)
Using cached primePy-1.3-py3-none-any.whl (4.0 kB)
Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 55.9 MB/s  0:00:00
Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)
Using cached typer-0.20.0-py3-none-any.whl (47 kB)
Using cached click-8.3.0-py3-none-any.whl (107 kB)
Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)
Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)
Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)
Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)
Using cached colorlog-6.10.1-py3-none-any.whl (11 kB)
Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)
Using cached HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)
Using cached ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)
Using cached ruamel.yaml.clib-0.2.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)
Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)
Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)
Using cached mako-1.3.10-py3-none-any.whl (78 kB)
Using cached networkx-3.5-py3-none-any.whl (2.0 MB)
Using cached pycparser-2.23-py3-none-any.whl (118 kB)
Using cached pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)
Using cached requests-2.32.5-py3-none-any.whl (64 kB)
Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)
Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)
Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)
Using cached sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)
Installing collected packages: sortedcontainers, pytz, primePy, nvidia-cusparselt-cu12, mpmath, flatbuffers, docopt, antlr4-python3-runtime, yt-dlp, urllib3, tzdata, typing-extensions, triton, tqdm, threadpoolctl, tabulate, sympy, six, shellingham, sentencepiece, semver, safetensors, ruamel.yaml.clib, regex, PyYAML, pyparsing, pygments, pycparser, protobuf, propcache, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, mdurl, MarkupSafe, kiwisolver, joblib, idna, humanfriendly, hf-xet, greenlet, fsspec, frozenlist, fonttools, filelock, einops, cycler, colorlog, click, charset_normalizer, certifi, av, attrs, aiohappyeyeballs, yarl, tensorboardX, sqlalchemy, scipy, ruamel.yaml, requests, python-dateutil, omegaconf, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nltk, markdown-it-py, Mako, lightning-utilities, jinja2, ctranslate2, contourpy, coloredlogs, cffi, aiosignal, soundfile, scikit-learn, rich, pyannote.core, pandas, onnxruntime, nvidia-cusolver-cu12, matplotlib, hyperpyyaml, huggingface_hub, alembic, aiohttp, typer, torch, tokenizers, optuna, transformers, torchmetrics, torchaudio, pytorch_metric_learning, pyannote.database, julius, faster-whisper, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.pipeline, pyannote.metrics, torch_audiomentations, lightning, pyannote-audio, whisperx

Successfully installed Mako-1.3.10 MarkupSafe-3.0.3 PyYAML-6.0.3 aiohappyeyeballs-2.6.1 aiohttp-3.13.1 aiosignal-1.4.0 alembic-1.17.0 antlr4-python3-runtime-4.9.3 asteroid-filterbanks-0.4.0 attrs-25.4.0 av-15.1.0 certifi-2025.10.5 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.0 coloredlogs-15.0.1 colorlog-6.10.1 contourpy-1.3.3 ctranslate2-4.6.0 cycler-0.12.1 docopt-0.6.2 einops-0.8.1 faster-whisper-1.2.0 filelock-3.20.0 flatbuffers-25.9.23 fonttools-4.60.1 frozenlist-1.8.0 fsspec-2025.9.0 greenlet-3.2.4 hf-xet-1.1.10 huggingface_hub-0.36.0 humanfriendly-10.0 hyperpyyaml-1.2.2 idna-3.11 jinja2-3.1.6 joblib-1.5.2 julius-0.2.7 kiwisolver-1.4.9 lightning-2.5.5 lightning-utilities-0.15.2 markdown-it-py-4.0.0 matplotlib-3.10.7 mdurl-0.1.2 mpmath-1.3.0 multidict-6.7.0 networkx-3.5 nltk-3.9.2 numpy-2.0.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 omegaconf-2.3.0 onnxruntime-1.23.2 optuna-4.5.0 packaging-25.0 pandas-2.2.3 pillow-12.0.0 primePy-1.3 propcache-0.4.1 protobuf-6.33.0 pyannote-audio-3.4.0 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pycparser-2.23 pygments-2.19.2 pyparsing-3.2.5 python-dateutil-2.9.0.post0 pytorch-lightning-2.5.5 pytorch_metric_learning-2.9.0 pytz-2025.2 regex-2025.10.23 requests-2.32.5 rich-14.2.0 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.14 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.16.2 semver-3.0.4 sentencepiece-0.2.1 shellingham-1.5.4 six-1.17.0 sortedcontainers-2.4.0 soundfile-0.13.1 speechbrain-1.0.3 sqlalchemy-2.0.44 sympy-1.14.0 tabulate-0.9.0 tensorboardX-2.6.4 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.8.0 torch-pitch-shift-1.2.5 torch_audiomentations-0.12.0 torchaudio-2.8.0 torchmetrics-1.8.2 tqdm-4.67.1 transformers-4.57.1 triton-3.4.0 typer-0.20.0 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0 whisperx-3.7.4 yarl-1.22.0 yt-dlp-2025.10.22
Collecting openai-whisper (from -r requirements.txt (line 1))
  Using cached openai_whisper-20250625-py3-none-any.whl
Requirement already satisfied: yt-dlp in ./whisper_env/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2025.10.22)
Collecting ffmpeg-python (from -r requirements.txt (line 3))
  Using cached ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)
Collecting more-itertools (from openai-whisper->-r requirements.txt (line 1))
  Using cached more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)
Collecting numba (from openai-whisper->-r requirements.txt (line 1))
  Using cached numba-0.62.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)
Requirement already satisfied: numpy in ./whisper_env/lib/python3.11/site-packages (from openai-whisper->-r requirements.txt (line 1)) (2.0.2)
Collecting tiktoken (from openai-whisper->-r requirements.txt (line 1))
  Using cached tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.7 kB)
Requirement already satisfied: torch in ./whisper_env/lib/python3.11/site-packages (from openai-whisper->-r requirements.txt (line 1)) (2.8.0)
Requirement already satisfied: tqdm in ./whisper_env/lib/python3.11/site-packages (from openai-whisper->-r requirements.txt (line 1)) (4.67.1)
Requirement already satisfied: triton>=2 in ./whisper_env/lib/python3.11/site-packages (from openai-whisper->-r requirements.txt (line 1)) (3.4.0)
Collecting future (from ffmpeg-python->-r requirements.txt (line 3))
  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)
Requirement already satisfied: setuptools>=40.8.0 in ./whisper_env/lib/python3.11/site-packages (from triton>=2->openai-whisper->-r requirements.txt (line 1)) (65.5.0)
Collecting llvmlite<0.46,>=0.45.0dev0 (from numba->openai-whisper->-r requirements.txt (line 1))
  Using cached llvmlite-0.45.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)
Requirement already satisfied: regex>=2022.1.18 in ./whisper_env/lib/python3.11/site-packages (from tiktoken->openai-whisper->-r requirements.txt (line 1)) (2025.10.23)
Requirement already satisfied: requests>=2.26.0 in ./whisper_env/lib/python3.11/site-packages (from tiktoken->openai-whisper->-r requirements.txt (line 1)) (2.32.5)
Requirement already satisfied: charset_normalizer<4,>=2 in ./whisper_env/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper->-r requirements.txt (line 1)) (3.4.4)
Requirement already satisfied: idna<4,>=2.5 in ./whisper_env/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper->-r requirements.txt (line 1)) (3.11)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./whisper_env/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper->-r requirements.txt (line 1)) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in ./whisper_env/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper->-r requirements.txt (line 1)) (2025.10.5)
Requirement already satisfied: filelock in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (3.20.0)
Requirement already satisfied: typing-extensions>=4.10.0 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (4.15.0)
Requirement already satisfied: sympy>=1.13.3 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (1.14.0)
Requirement already satisfied: networkx in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (3.5)
Requirement already satisfied: jinja2 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (3.1.6)
Requirement already satisfied: fsspec in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (2025.9.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (2.27.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./whisper_env/lib/python3.11/site-packages (from torch->openai-whisper->-r requirements.txt (line 1)) (1.13.1.3)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./whisper_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch->openai-whisper->-r requirements.txt (line 1)) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in ./whisper_env/lib/python3.11/site-packages (from jinja2->torch->openai-whisper->-r requirements.txt (line 1)) (3.0.3)
Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)
Using cached future-1.0.0-py3-none-any.whl (491 kB)
Using cached more_itertools-10.8.0-py3-none-any.whl (69 kB)
Using cached numba-0.62.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)
Using cached llvmlite-0.45.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)
Using cached tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl (1.2 MB)
Installing collected packages: more-itertools, llvmlite, future, tiktoken, numba, ffmpeg-python, openai-whisper

Successfully installed ffmpeg-python-0.2.0 future-1.0.0 llvmlite-0.45.1 more-itertools-10.8.0 numba-0.62.1 openai-whisper-20250625 tiktoken-0.12.0
[youtube] Extracting URL: https://www.youtube.com/watch?v=83jt-xOJok4
Downloading audio from: https://www.youtube.com/watch?v=83jt-xOJok4
[youtube] 83jt-xOJok4: Downloading webpage
[youtube] 83jt-xOJok4: Downloading android sdkless player API JSON
[youtube] 83jt-xOJok4: Downloading tv client config
[youtube] 83jt-xOJok4: Downloading tv player API JSON
[youtube] 83jt-xOJok4: Downloading web safari player API JSON
[youtube] 83jt-xOJok4: Downloading m3u8 information
[info] 83jt-xOJok4: Downloading 1 format(s): 251
[download] output/Axon Body 3 Video 2022 09 15 1723 X60A0524C.webm has already been downloaded
[download] 100% of   20.08MiB

Video title: Axon Body 3 Video 2022 09 15 1723 X60A0524C
Duration: 1323 seconds

Using device: cpu
Compute type: int8
No HuggingFace token - speaker diarization will be skipped

================================================================================
Step 1: Loading WhisperX model (base) on cpu
================================================================================
2025-10-23 11:04:14 - whisperx.asr - INFO - No language specified, language will be detected for each audio file (increases inference time)
2025-10-23 11:04:14 - whisperx.vads.pyannote - INFO - Performing voice activity detection using Pyannote...
Model was trained with pyannote.audio 0.0.1, yours is 3.4.0. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.8.0+cu128. Bad things might happen unless you revert torch to 1.x.

Loading audio file: output/Axon Body 3 Video 2022 09 15 1723 X60A0524C.webm

================================================================================
Step 2: Transcribing audio
================================================================================
2025-10-23 11:04:48 - whisperx.asr - INFO - Detected language: en (0.40) in first 30s of audio

================================================================================
Step 3: Aligning transcription
================================================================================

================================================================================
Note: Skipping speaker diarization (no HuggingFace token provided)
To enable diarization, set HF_TOKEN environment variable or pass hf_token parameter
================================================================================

Transcript saved to: output/transcript_20251023_110651.txt
Detailed transcript with timestamps saved to: output/transcript_20251023_110651.json
Human-readable timestamped transcript saved to: output/transcript_20251023_110651_timestamped.txt

================================================================================
TRANSCRIPT:
================================================================================
[Unknown]:  Let's go. Alright, thanks.Come in.Kurt?Good?You got a paper towel right here?Like a napkin and fuckin' sweat and the balls on. I don't know if it's going to work. I agree.We get to the side. No, no, no, no, no, no, no. If it's part of the investigation, we don't have to act.It's not for investigation.It is.You don't know what we need.It's not to happen over here.Okay, we need to make it bigger, that's what we're saying.I'm just giving you notice of the merger that this is private promise.I'm just being polite and honorable.Okay.This is private property. They're giving you notice.Okay.Okay.What I'm telling you is that if it comes down and that we need to come on it, we will.That's all I'm saying.No, you will not.That you can't do that.That's not how it works.Okay.Can we be, can we be real happy?Have I, have I, have I been disrespectful?Have I say anything?I don't know.When I say that, I'm just giving you notice that this is private property.What I'm saying?And I'm going to help and assist. But this is probably the problem.What I am telling you, nothing happened over here.I am saying.Nothing happened over here.I'm literally trying to just talk.And you just keep cutting me off.I'm just trying to have a conversation.I'm literally trying to explain something.If it necessitates, we will.That's all I'm saying.Now, a grant, I wasn't here.I don't know.I don't know what happened.All I'm saying.No one came on my land.Okay, because you said no in the table, right? So before there was a situation about it, all I was trying to say, if the situation necessitated and it became apparent and necessary, we would take the space.That's all I was saying?I didn't say anything about it.So it was okay to steal?If we just needed to block it off for whatever reason.No, you just said it was okay to take.I was making sure that the video says the same thing, you're true saying.You said it's okay to steal. Am I permanently depriving you of it?Yes, you said.You just said, take.Hasn't take this place.No, no, no.Yeah, yeah.That didn't mean stealing.So we're not doing any stealing.I'm not going to steal.I'm not going to steal.I'm not going to steal.Can I pick up a walk away with your house?That's not the point.Office of virtue?That's not the point.We're talking law.You said, take.We're not taking anything.I'm going to take it from you.You're not taking it from me.We're going to be honorable.OK, so if we want to talk law, right, you have a reasonable expectation of privacy, correct?Reasonable?No. No, I'm not part of that.No, no.Okay, let's talk about it.You want to get into a lesson today?I'm trying to be honorable.But do you understand jurisdiction?I do.That's what I'm trying to explain to you.The Fourth Amendment provides you a reasonable expectation.I'm not a U.S. citizen.First of all, that's the more.Being that you live in United States, No, I don't.You have a way in there.You have a way in there.You know that?That just happens in B and 9, which is a part of the United States, okay?Because you are in this vicinity, right?We'll say you're provided a certain exemption, right?You're provided certain protections and that's just policing or whatever it is, right?I'm not bothering you, right?You don't bother me.So all I was trying to say was, okay, you were trying, okay, go in this scenario with that. If somebody says, hey, we need to block this off because X or X and Y would happen.Yes.And I would say, hey, we don't have to act.We're just going to do it at this time.We're not going to take it forever until they're done.Then we can, we can be done with it.But all I'm saying is that as soon as the tape went up, you were just like, no, no, no, no, no, no, no.And I'm just like, hey, before we get there, if we need it, you know, that's all I was doing. You can't say you can't say I didn't say he didn't say anything You did I'll give you that I will I will consider that that you did say that now I'm not right now I'm not saying that I'm not trying to be a jerk I'm not trying to be rude obviously your property is your property I'm not gonna take anything for anybody that I don't need or I don't want or I don't have to take right all I'm saying was that if we needed to put crime scene save up across the yard for a brief moment just to check himself out if a street one happened to go somewhere what No, again, I'm just saying like hypothetically speaking, so like this is for anybody's house.You know, if a house was randomly struggling, we may have had something to do with it.If we have to take tape, obviously people don't agree with it, but obviously, I just want to at least explain understand why, right?All those I can't notice or whatever can happen illegally.Absolutely.I understand that.So, civil. What was the word you kept what was the word you can't use it?Honorable yeah Honorable yeah, okay, we're doing what you say Absolutely But this is what you want.The one that I'm pointing there.You can go.We can deduce that I couldn't out park right there.I stay literally right there.Oh, okay.Your car can make it.But you can take the stuff into the house and once the tape is down, I don't know how long it's going to be, but if you want to walk in your house.Yeah, you can walk around the tape.It's everything on the right side.It's fine.So you can get your stuff and you can come back for your car later if you want.Well, obviously you can have to. It's a good touch here. Thank you very much. You gotta get out.I'm gonna go live, we go live to take.Excuse me.I gotta get my friend for this. Merchant.Merchant.Merchant.Merchant.Merchant.Merchant. Don't put it on that first piece of there.It might not make it bad. I think, well, my camera's on, I just want to let you know.I really want to watch you play something.You did?Those guys came back and worked for quarter, quarter, quarter.Well, you never played four halves.Yeah.And then, well, three.Yeah, we never played three, but then we did.And the third, I was gassed out, man.I didn't have any more juice in the legs.What's up?They're playing here. It was a good little game.The first two halves were the best, but that third half, that third, 30 minutes, I just couldn't hang.What do you mean you had this short stuff?You had it?I know, it was all my tiptoes. Who is this?It must be us.Yeah, I'll stick it. That was awesome.That was awesome.That was brilliant. Hey, Chief.Sir, what's your name?Sorry, we carried on an entire conversation.Paid?Paid.Paid?Paid?I got an earpiece in there.I know.What were you from?Originally?Yeah, originally from New York.It's not me.Oh, really from New York?Yeah, you never heard of the ancient people who actually are the airs of this land or the bays and elves.I know you know that.Don't tell me you don't know that.You so... Because you will be really... I'd really be, I'd be not, that would be that.You'd be doing the problem, you would be doing the problem done on it, done our ability shit.Cause everybody knows about the Bayes and Elves.So everybody knows the more.So don't, historically speaking, you want to, you want a Supreme Court case to get?No, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, No, no, but that's one case that I'm gonna grab it I'm gonna tell you it is it's the heirs of Turner versus United States Heirs of Turner?The heirs of Turner.Oh heirs like the heirs.Okay.Get to the land right right versus the United States Okay, tell you right then the first first synopsis of the paragraph.We own the land.Okay.I'm not so that's all I'm saying I just wanted to share that with you so anything that you came out of that it would kind of like I'm going to write it down.See that?What's that?That's my joy.I think you, I think you, I think you BS in me, but I promise you, I'm not hairs of turner.That's the exact, but I think that's the type of angle we should come up.Versus your ass.Yeah.I will look at it.I give you my word, Mr. Bill.Yeah, no.So, no, historic.So, what were you, what were you about to say?Historicly, I am familiar with the Bays.Yes.If you guys are familiar with it.Historicly, I am familiar. Um, to say I am as knowledgeable as one like yourself is would be happy line.And my normal experience in the county within our generally sovereign citizens at work.Okay.I know.So you know, are you college educated?Yeah.Okay.You made with etymology? Not as much as one should be.Oh, but yes.So when you say sovereign citizens, it's no such thing.So you say that's why I asked you the question before I asked you the question, were you educated?I said etymology.Etymology is the root of every word.So it gives you the true meaning, not what someone wrote in a dictionary.So insane sovereign citizenship can't be sovereign. and we're part of a more science temple, Jeff Governing.I'm going to tell you what it came from.805 statues, hers revised statues in Illinois.If you look up hers revised statues in Illinois, it gives us our sovereign power just like the Vatican.So you understand that you can make the correlation in your mind.Makes sense?It does.That's all it is.That's it.It ain't no more to it than that.So we're going to confuse it. And try to make up other stuff.That's the correlation.So now you got in your mind.Okay, it's just like I've been looking at one of the pope's ministers.Yes, that's who I am.That's the correlation to keep it simple in your mind so you don't have to think of something. or use the word you just use, which is actually disrespectful number one, it is.But you didn't know.Now, you know.Right.Well, you even still, I'm gonna say, I'll apologize.Never be sorry.Never be sorry.Sorry to stay to be in.Right.Now, you put your knoll now.You're educated.Absolutely.So that's it.You can knock him.Okay.Now, so you can, in your mind, you got, okay, this ain't no.He just, he just, he just, he just, right?Which he has rights to.Everyone has rights.Absolutely.And it's been acknowledged by all the people that know, rather than all down.Everyone knows our status. Right.They know it.So it's on the record with the Ike Knight on the Supreme Court but with the Federal Court.And in the county.Right.From my name, it gives you who I am.Commercially, and as a man on the land.Both. I'm just trying to educate you not being this so you won't be English like most of you don't mention the time on him But now you now you get in your mind.Okay.I got it.I see what he's saying It's simple, so but most of them don't know that or some know and still try to be What do you call it?No, no, no, no, not honorable.Oh, the key word Just keep it honorable, like that word.Yes, but it's fitting.What we did with two governments and they're substituted.You were substituted, right, of the US government.Yes, correct.So, that's all, that's all what it is.Now, what these young, well, what they were doing, I don't know what happened.I was going to back in my house on this car when I heard shots fired.Something less than pleasurable, we'll say, like that.And which brings me back to the original point of, Because of what it is, there's no telling what they might ask of people nearby.So I understand.I'll explain it like this.Let's say if I'm running after somebody and I lose sight of them, you want to start a circle as big as you can and collapse it as you can come in.So I don't know where everything's because I wasn't even here.I don't know where everything was when it happened.Normally, we'll always go bigger as a failsafe and then once we know exactly what honing in. But the conversation that you and I had is the one that we have a lot of times because some people are just like hey, you know, just my property you can't be here And as respectfully as we have to explain is that hey, I understand that where I'm not here for forever.I'm not here to do I know what you was right and I want to I really want to have some education That's what I really want to know I appreciate that's my whole goal never to go to learn If you shouldn't be don't be unintelligent to have a vehicle ever bought to subscribe.There's no channel nine Hey Mr. Bay, should I see you again?Absolutely.Absolutely.I appreciate that conversation. You almost got it.It's time to come to cream.I was kind of surprised. I don't see.I don't see.Sorry, do we have people watching?Yes, sir.I'll sit on the side with him if he needs to. Oh, yeah.
================================================================================

================================================================================
Processing complete!
================================================================================
Audio file: output/Axon Body 3 Video 2022 09 15 1723 X60A0524C.webm
Transcript: output/transcript_20251023_110651.txt
Timestamped transcript: output/transcript_20251023_110651_timestamped.txt
Detailed output: output/transcript_20251023_110651.json
Transcription completed!
