Requirement already satisfied: pip in ./whisper_env/lib/python3.11/site-packages (24.0)
Collecting pip
  Using cached pip-25.3-py3-none-any.whl.metadata (4.7 kB)
Using cached pip-25.3-py3-none-any.whl (1.8 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 24.0
    Uninstalling pip-24.0:
      Successfully uninstalled pip-24.0
Successfully installed pip-25.3
Collecting whisperx
  Using cached whisperx-3.7.4-py3-none-any.whl.metadata (16 kB)
Collecting yt-dlp
  Using cached yt_dlp-2025.10.22-py3-none-any.whl.metadata (176 kB)
Collecting torch
  Using cached torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)
Collecting ctranslate2>=4.5.0 (from whisperx)
  Using cached ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Collecting faster-whisper>=1.1.1 (from whisperx)
  Using cached faster_whisper-1.2.0-py3-none-any.whl.metadata (16 kB)
Collecting nltk>=3.9.1 (from whisperx)
  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)
Collecting numpy<2.1.0,>=2.0.2 (from whisperx)
  Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)
Collecting pandas<2.3.0,>=2.2.3 (from whisperx)
  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)
Collecting av<16.0.0 (from whisperx)
  Using cached av-15.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)
Collecting pyannote-audio<4.0.0,>=3.3.2 (from whisperx)
  Using cached pyannote_audio-3.4.0-py2.py3-none-any.whl.metadata (11 kB)
Collecting torch
  Using cached torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)
Collecting torchaudio~=2.8.0 (from whisperx)
  Using cached torchaudio-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.2 kB)
Collecting transformers>=4.48.0 (from whisperx)
  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)
Collecting triton>=3.3.0 (from whisperx)
  Using cached triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)
Collecting filelock (from torch)
  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)
Collecting typing-extensions>=4.10.0 (from torch)
  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting sympy>=1.13.3 (from torch)
  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch)
  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch)
  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch)
  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)
Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)
  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)
  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)
  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)
  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)
  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)
  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-curand-cu12==10.3.9.90 (from torch)
  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)
  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)
  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)
  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)
Collecting nvidia-nccl-cu12==2.27.3 (from torch)
  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)
Collecting nvidia-nvtx-cu12==12.8.90 (from torch)
  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)
  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)
  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
Collecting triton>=3.3.0 (from whisperx)
  Using cached triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)
Requirement already satisfied: setuptools>=40.8.0 in ./whisper_env/lib/python3.11/site-packages (from triton>=3.3.0->whisperx) (65.5.0)
Collecting python-dateutil>=2.8.2 (from pandas<2.3.0,>=2.2.3->whisperx)
  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.2.3->whisperx)
  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)
Collecting tzdata>=2022.7 (from pandas<2.3.0,>=2.2.3->whisperx)
  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)
Collecting asteroid-filterbanks>=0.4 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)
Collecting einops>=0.6.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)
Collecting huggingface_hub>=0.13.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached huggingface_hub-1.0.1-py3-none-any.whl.metadata (13 kB)
Collecting lightning>=2.0.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached lightning-2.5.5-py3-none-any.whl.metadata (39 kB)
Collecting omegaconf<3.0,>=2.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)
Collecting pyannote.core<6.0,>=5.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)
Collecting pyannote.database<6.0,>=5.0.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)
Collecting pyannote.metrics<4.0,>=3.2 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)
Collecting pyannote.pipeline<4.0,>=3.0.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)
Collecting pytorch_metric_learning>=2.1.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pytorch_metric_learning-2.9.0-py3-none-any.whl.metadata (18 kB)
Collecting rich>=12.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)
Collecting semver>=3.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)
Collecting soundfile>=0.12.1 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)
Collecting speechbrain>=1.0.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)
Collecting tensorboardX>=2.6 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)
Collecting torch_audiomentations>=0.11.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)
Collecting torchmetrics>=0.11.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)
Collecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0,>=2.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl
Collecting PyYAML>=5.1.0 (from omegaconf<3.0,>=2.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)
Collecting sortedcontainers>=2.0.4 (from pyannote.core<6.0,>=5.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)
Collecting scipy>=1.1 (from pyannote.core<6.0,>=5.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)
Collecting typer>=0.12.1 (from pyannote.database<6.0,>=5.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached typer-0.20.0-py3-none-any.whl.metadata (16 kB)
Collecting scikit-learn>=0.17.1 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)
Collecting docopt>=0.6.2 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached docopt-0.6.2-py2.py3-none-any.whl
Collecting tabulate>=0.7.7 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)
Collecting matplotlib>=2.0.0 (from pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)
Collecting optuna>=3.1 (from pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached optuna-4.5.0-py3-none-any.whl.metadata (17 kB)
Collecting tqdm>=4.29.1 (from pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
Collecting tokenizers<1,>=0.13 (from faster-whisper>=1.1.1->whisperx)
  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)
Collecting onnxruntime<2,>=1.14 (from faster-whisper>=1.1.1->whisperx)
  Using cached onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)
Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx)
  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)
Collecting flatbuffers (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx)
  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)
Collecting packaging (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx)
  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
Collecting protobuf (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx)
  Using cached protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)
Collecting httpx<1,>=0.23.0 (from huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)
Collecting shellingham (from huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)
Collecting typer-slim (from huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)
Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)
Collecting anyio (from httpx<1,>=0.23.0->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)
Collecting certifi (from httpx<1,>=0.23.0->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)
Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)
Collecting idna (from httpx<1,>=0.23.0->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)
Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)
Collecting pytorch-lightning (from lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)
Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached aiohttp-3.13.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)
Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)
Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)
Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)
Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)
Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)
Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)
Collecting contourpy>=1.0.1 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)
Collecting cycler>=0.10 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
Collecting fonttools>=4.22.0 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)
Collecting kiwisolver>=1.3.1 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)
Collecting pillow>=8 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)
Collecting pyparsing>=3 (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)
Collecting click (from nltk>=3.9.1->whisperx)
  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)
Collecting joblib (from nltk>=3.9.1->whisperx)
  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)
Collecting regex>=2021.8.3 (from nltk>=3.9.1->whisperx)
  Using cached regex-2025.10.23-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)
Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached alembic-1.17.0-py3-none-any.whl.metadata (7.2 kB)
Collecting colorlog (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)
Collecting sqlalchemy>=1.4.2 (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached sqlalchemy-2.0.44-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)
Collecting Mako (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)
Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.2.3->whisperx)
  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting markdown-it-py>=2.2.0 (from rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)
Collecting pygments<3.0.0,>=2.13.0 (from rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)
Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)
Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.17.1->pyannote.metrics<4.0,>=3.2->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
Collecting cffi>=1.0 (from soundfile>=0.12.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)
Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)
Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)
Collecting sentencepiece (from speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)
Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)
  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Collecting julius<0.3,>=0.2.3 (from torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached julius-0.2.7-py3-none-any.whl
Collecting torch-pitch-shift>=1.2.2 (from torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)
Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch_audiomentations>=0.11.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached primePy-1.3-py3-none-any.whl.metadata (4.8 kB)
Collecting huggingface_hub>=0.13.0 (from pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)
Collecting requests (from transformers>=4.48.0->whisperx)
  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
Collecting safetensors>=0.4.3 (from transformers>=4.48.0->whisperx)
  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)
Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->huggingface_hub>=0.13.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)
Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx)
  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)
Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)
Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote-audio<4.0.0,>=3.3.2->whisperx)
  Using cached ruamel.yaml.clib-0.2.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch)
  Using cached markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)
Collecting charset_normalizer<4,>=2 (from requests->transformers>=4.48.0->whisperx)
  Using cached charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)
Collecting urllib3<3,>=1.21.1 (from requests->transformers>=4.48.0->whisperx)
  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)
Using cached whisperx-3.7.4-py3-none-any.whl (16.5 MB)
Using cached torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)
Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)
Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)
Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)
Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)
Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)
Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)
Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)
Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)
Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)
Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)
Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)
Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)
Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)
Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)
Using cached triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)
Using cached av-15.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.6 MB)
Using cached numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)
Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)
Using cached pyannote_audio-3.4.0-py2.py3-none-any.whl (897 kB)
Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)
Using cached pyannote.core-5.0.0-py3-none-any.whl (58 kB)
Using cached pyannote.database-5.1.3-py3-none-any.whl (48 kB)
Using cached pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)
Using cached pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)
Using cached torchaudio-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.0 MB)
Using cached yt_dlp-2025.10.22-py3-none-any.whl (3.2 MB)
Using cached asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)
Using cached ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)
Using cached pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)
Using cached einops-0.8.1-py3-none-any.whl (64 kB)
Using cached faster_whisper-1.2.0-py3-none-any.whl (1.1 MB)
Using cached onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)
Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
Using cached filelock-3.20.0-py3-none-any.whl (16 kB)
Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)
Using cached lightning-2.5.5-py3-none-any.whl (828 kB)
Using cached lightning_utilities-0.15.2-py3-none-any.whl (29 kB)
Using cached packaging-25.0-py3-none-any.whl (66 kB)
Using cached torchmetrics-1.8.2-py3-none-any.whl (983 kB)
Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)
Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Using cached aiohttp-3.13.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)
Using cached multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)
Using cached yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (365 kB)
Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)
Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)
Using cached attrs-25.4.0-py3-none-any.whl (67 kB)
Using cached frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (231 kB)
Using cached idna-3.11-py3-none-any.whl (71 kB)
Using cached matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)
Using cached contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)
Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)
Using cached fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)
Using cached kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)
Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)
Using cached optuna-4.5.0-py3-none-any.whl (400 kB)
Using cached alembic-1.17.0-py3-none-any.whl (247 kB)
Using cached pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)
Using cached propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (210 kB)
Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)
Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Using cached pytorch_metric_learning-2.9.0-py3-none-any.whl (127 kB)
Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)
Using cached regex-2025.10.23-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)
Using cached rich-14.2.0-py3-none-any.whl (243 kB)
Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)
Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)
Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)
Using cached scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)
Using cached joblib-1.5.2-py3-none-any.whl (308 kB)
Using cached scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)
Using cached semver-3.0.4-py3-none-any.whl (17 kB)
Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)
Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)
Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)
Using cached cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (215 kB)
Using cached speechbrain-1.0.3-py3-none-any.whl (864 kB)
Using cached sqlalchemy-2.0.44-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
Using cached greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (587 kB)
Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)
Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)
Using cached tensorboardx-2.6.4-py3-none-any.whl (87 kB)
Using cached protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)
Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
Using cached torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)
Using cached torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)
Using cached primePy-1.3-py3-none-any.whl (4.0 kB)
Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)
Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)
Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)
Using cached typer-0.20.0-py3-none-any.whl (47 kB)
Using cached click-8.3.0-py3-none-any.whl (107 kB)
Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)
Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)
Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)
Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)
Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)
Using cached colorlog-6.10.1-py3-none-any.whl (11 kB)
Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)
Using cached HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)
Using cached ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)
Using cached ruamel.yaml.clib-0.2.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)
Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)
Using cached markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)
Using cached mako-1.3.10-py3-none-any.whl (78 kB)
Using cached networkx-3.5-py3-none-any.whl (2.0 MB)
Using cached pycparser-2.23-py3-none-any.whl (118 kB)
Using cached pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)
Using cached requests-2.32.5-py3-none-any.whl (64 kB)
Using cached charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)
Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)
Using cached sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)
Installing collected packages: sortedcontainers, pytz, primePy, nvidia-cusparselt-cu12, mpmath, flatbuffers, docopt, antlr4-python3-runtime, yt-dlp, urllib3, tzdata, typing-extensions, triton, tqdm, threadpoolctl, tabulate, sympy, six, shellingham, sentencepiece, semver, safetensors, ruamel.yaml.clib, regex, PyYAML, pyparsing, pygments, pycparser, protobuf, propcache, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, mdurl, MarkupSafe, kiwisolver, joblib, idna, humanfriendly, hf-xet, greenlet, fsspec, frozenlist, fonttools, filelock, einops, cycler, colorlog, click, charset_normalizer, certifi, av, attrs, aiohappyeyeballs, yarl, tensorboardX, sqlalchemy, scipy, ruamel.yaml, requests, python-dateutil, omegaconf, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nltk, markdown-it-py, Mako, lightning-utilities, jinja2, ctranslate2, contourpy, coloredlogs, cffi, aiosignal, soundfile, scikit-learn, rich, pyannote.core, pandas, onnxruntime, nvidia-cusolver-cu12, matplotlib, hyperpyyaml, huggingface_hub, alembic, aiohttp, typer, torch, tokenizers, optuna, transformers, torchmetrics, torchaudio, pytorch_metric_learning, pyannote.database, julius, faster-whisper, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.pipeline, pyannote.metrics, torch_audiomentations, lightning, pyannote-audio, whisperx

Successfully installed Mako-1.3.10 MarkupSafe-3.0.3 PyYAML-6.0.3 aiohappyeyeballs-2.6.1 aiohttp-3.13.1 aiosignal-1.4.0 alembic-1.17.0 antlr4-python3-runtime-4.9.3 asteroid-filterbanks-0.4.0 attrs-25.4.0 av-15.1.0 certifi-2025.10.5 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.0 coloredlogs-15.0.1 colorlog-6.10.1 contourpy-1.3.3 ctranslate2-4.6.0 cycler-0.12.1 docopt-0.6.2 einops-0.8.1 faster-whisper-1.2.0 filelock-3.20.0 flatbuffers-25.9.23 fonttools-4.60.1 frozenlist-1.8.0 fsspec-2025.9.0 greenlet-3.2.4 hf-xet-1.2.0 huggingface_hub-0.36.0 humanfriendly-10.0 hyperpyyaml-1.2.2 idna-3.11 jinja2-3.1.6 joblib-1.5.2 julius-0.2.7 kiwisolver-1.4.9 lightning-2.5.5 lightning-utilities-0.15.2 markdown-it-py-4.0.0 matplotlib-3.10.7 mdurl-0.1.2 mpmath-1.3.0 multidict-6.7.0 networkx-3.5 nltk-3.9.2 numpy-2.0.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 omegaconf-2.3.0 onnxruntime-1.23.2 optuna-4.5.0 packaging-25.0 pandas-2.2.3 pillow-12.0.0 primePy-1.3 propcache-0.4.1 protobuf-6.33.0 pyannote-audio-3.4.0 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pycparser-2.23 pygments-2.19.2 pyparsing-3.2.5 python-dateutil-2.9.0.post0 pytorch-lightning-2.5.5 pytorch_metric_learning-2.9.0 pytz-2025.2 regex-2025.10.23 requests-2.32.5 rich-14.2.0 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.14 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.16.3 semver-3.0.4 sentencepiece-0.2.1 shellingham-1.5.4 six-1.17.0 sortedcontainers-2.4.0 soundfile-0.13.1 speechbrain-1.0.3 sqlalchemy-2.0.44 sympy-1.14.0 tabulate-0.9.0 tensorboardX-2.6.4 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.8.0 torch-pitch-shift-1.2.5 torch_audiomentations-0.12.0 torchaudio-2.8.0 torchmetrics-1.8.2 tqdm-4.67.1 transformers-4.57.1 triton-3.4.0 typer-0.20.0 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0 whisperx-3.7.4 yarl-1.22.0 yt-dlp-2025.10.22
Collecting opencv-python
  Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)
Requirement already satisfied: Pillow in ./whisper_env/lib/python3.11/site-packages (12.0.0)
Requirement already satisfied: transformers in ./whisper_env/lib/python3.11/site-packages (4.57.1)
Requirement already satisfied: numpy in ./whisper_env/lib/python3.11/site-packages (2.0.2)
Requirement already satisfied: scipy in ./whisper_env/lib/python3.11/site-packages (1.16.3)
Requirement already satisfied: filelock in ./whisper_env/lib/python3.11/site-packages (from transformers) (3.20.0)
Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./whisper_env/lib/python3.11/site-packages (from transformers) (0.36.0)
Requirement already satisfied: packaging>=20.0 in ./whisper_env/lib/python3.11/site-packages (from transformers) (25.0)
Requirement already satisfied: pyyaml>=5.1 in ./whisper_env/lib/python3.11/site-packages (from transformers) (6.0.3)
Requirement already satisfied: regex!=2019.12.17 in ./whisper_env/lib/python3.11/site-packages (from transformers) (2025.10.23)
Requirement already satisfied: requests in ./whisper_env/lib/python3.11/site-packages (from transformers) (2.32.5)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./whisper_env/lib/python3.11/site-packages (from transformers) (0.22.1)
Requirement already satisfied: safetensors>=0.4.3 in ./whisper_env/lib/python3.11/site-packages (from transformers) (0.6.2)
Requirement already satisfied: tqdm>=4.27 in ./whisper_env/lib/python3.11/site-packages (from transformers) (4.67.1)
Requirement already satisfied: fsspec>=2023.5.0 in ./whisper_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in ./whisper_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./whisper_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)
Requirement already satisfied: charset_normalizer<4,>=2 in ./whisper_env/lib/python3.11/site-packages (from requests->transformers) (3.4.4)
Requirement already satisfied: idna<4,>=2.5 in ./whisper_env/lib/python3.11/site-packages (from requests->transformers) (3.11)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./whisper_env/lib/python3.11/site-packages (from requests->transformers) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in ./whisper_env/lib/python3.11/site-packages (from requests->transformers) (2025.10.5)
Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)
Installing collected packages: opencv-python
Successfully installed opencv-python-4.12.0.88
Requirement already satisfied: whisperx in ./whisper_env/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (3.7.4)
Requirement already satisfied: yt-dlp in ./whisper_env/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2025.10.22)
Collecting ffmpeg-python (from -r requirements.txt (line 3))
  Using cached ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)
Requirement already satisfied: torch in ./whisper_env/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.8.0)
Requirement already satisfied: pyannote.audio in ./whisper_env/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (3.4.0)
Requirement already satisfied: opencv-python in ./whisper_env/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (4.12.0.88)
Requirement already satisfied: Pillow in ./whisper_env/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (12.0.0)
Requirement already satisfied: transformers in ./whisper_env/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (4.57.1)
Requirement already satisfied: numpy in ./whisper_env/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (2.0.2)
Requirement already satisfied: scipy in ./whisper_env/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (1.16.3)
Requirement already satisfied: ctranslate2>=4.5.0 in ./whisper_env/lib/python3.11/site-packages (from whisperx->-r requirements.txt (line 1)) (4.6.0)
Requirement already satisfied: faster-whisper>=1.1.1 in ./whisper_env/lib/python3.11/site-packages (from whisperx->-r requirements.txt (line 1)) (1.2.0)
Requirement already satisfied: nltk>=3.9.1 in ./whisper_env/lib/python3.11/site-packages (from whisperx->-r requirements.txt (line 1)) (3.9.2)
Requirement already satisfied: pandas<2.3.0,>=2.2.3 in ./whisper_env/lib/python3.11/site-packages (from whisperx->-r requirements.txt (line 1)) (2.2.3)
Requirement already satisfied: av<16.0.0 in ./whisper_env/lib/python3.11/site-packages (from whisperx->-r requirements.txt (line 1)) (15.1.0)
Requirement already satisfied: torchaudio~=2.8.0 in ./whisper_env/lib/python3.11/site-packages (from whisperx->-r requirements.txt (line 1)) (2.8.0)
Requirement already satisfied: triton>=3.3.0 in ./whisper_env/lib/python3.11/site-packages (from whisperx->-r requirements.txt (line 1)) (3.4.0)
Requirement already satisfied: filelock in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (3.20.0)
Requirement already satisfied: typing-extensions>=4.10.0 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (4.15.0)
Requirement already satisfied: sympy>=1.13.3 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (1.14.0)
Requirement already satisfied: networkx in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (3.5)
Requirement already satisfied: jinja2 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (3.1.6)
Requirement already satisfied: fsspec in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (2025.9.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (2.27.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./whisper_env/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (1.13.1.3)
Requirement already satisfied: setuptools>=40.8.0 in ./whisper_env/lib/python3.11/site-packages (from triton>=3.3.0->whisperx->-r requirements.txt (line 1)) (65.5.0)
Requirement already satisfied: asteroid-filterbanks>=0.4 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (0.4.0)
Requirement already satisfied: einops>=0.6.0 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (0.8.1)
Requirement already satisfied: huggingface_hub>=0.13.0 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (0.36.0)
Requirement already satisfied: lightning>=2.0.1 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (2.5.5)
Requirement already satisfied: omegaconf<3.0,>=2.1 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (2.3.0)
Requirement already satisfied: pyannote.core<6.0,>=5.0.0 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (5.0.0)
Requirement already satisfied: pyannote.database<6.0,>=5.0.1 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (5.1.3)
Requirement already satisfied: pyannote.metrics<4.0,>=3.2 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (3.2.1)
Requirement already satisfied: pyannote.pipeline<4.0,>=3.0.1 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (3.0.1)
Requirement already satisfied: pytorch_metric_learning>=2.1.0 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (2.9.0)
Requirement already satisfied: rich>=12.0.0 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (14.2.0)
Requirement already satisfied: semver>=3.0.0 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (3.0.4)
Requirement already satisfied: soundfile>=0.12.1 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (0.13.1)
Requirement already satisfied: speechbrain>=1.0.0 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (1.0.3)
Requirement already satisfied: tensorboardX>=2.6 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (2.6.4)
Requirement already satisfied: torch_audiomentations>=0.11.0 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (0.12.0)
Requirement already satisfied: torchmetrics>=0.11.0 in ./whisper_env/lib/python3.11/site-packages (from pyannote.audio->-r requirements.txt (line 5)) (1.8.2)
Requirement already satisfied: antlr4-python3-runtime==4.9.* in ./whisper_env/lib/python3.11/site-packages (from omegaconf<3.0,>=2.1->pyannote.audio->-r requirements.txt (line 5)) (4.9.3)
Requirement already satisfied: PyYAML>=5.1.0 in ./whisper_env/lib/python3.11/site-packages (from omegaconf<3.0,>=2.1->pyannote.audio->-r requirements.txt (line 5)) (6.0.3)
Requirement already satisfied: python-dateutil>=2.8.2 in ./whisper_env/lib/python3.11/site-packages (from pandas<2.3.0,>=2.2.3->whisperx->-r requirements.txt (line 1)) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in ./whisper_env/lib/python3.11/site-packages (from pandas<2.3.0,>=2.2.3->whisperx->-r requirements.txt (line 1)) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in ./whisper_env/lib/python3.11/site-packages (from pandas<2.3.0,>=2.2.3->whisperx->-r requirements.txt (line 1)) (2025.2)
Requirement already satisfied: sortedcontainers>=2.0.4 in ./whisper_env/lib/python3.11/site-packages (from pyannote.core<6.0,>=5.0.0->pyannote.audio->-r requirements.txt (line 5)) (2.4.0)
Requirement already satisfied: typer>=0.12.1 in ./whisper_env/lib/python3.11/site-packages (from pyannote.database<6.0,>=5.0.1->pyannote.audio->-r requirements.txt (line 5)) (0.20.0)
Requirement already satisfied: scikit-learn>=0.17.1 in ./whisper_env/lib/python3.11/site-packages (from pyannote.metrics<4.0,>=3.2->pyannote.audio->-r requirements.txt (line 5)) (1.7.2)
Requirement already satisfied: docopt>=0.6.2 in ./whisper_env/lib/python3.11/site-packages (from pyannote.metrics<4.0,>=3.2->pyannote.audio->-r requirements.txt (line 5)) (0.6.2)
Requirement already satisfied: tabulate>=0.7.7 in ./whisper_env/lib/python3.11/site-packages (from pyannote.metrics<4.0,>=3.2->pyannote.audio->-r requirements.txt (line 5)) (0.9.0)
Requirement already satisfied: matplotlib>=2.0.0 in ./whisper_env/lib/python3.11/site-packages (from pyannote.metrics<4.0,>=3.2->pyannote.audio->-r requirements.txt (line 5)) (3.10.7)
Requirement already satisfied: optuna>=3.1 in ./whisper_env/lib/python3.11/site-packages (from pyannote.pipeline<4.0,>=3.0.1->pyannote.audio->-r requirements.txt (line 5)) (4.5.0)
Requirement already satisfied: tqdm>=4.29.1 in ./whisper_env/lib/python3.11/site-packages (from pyannote.pipeline<4.0,>=3.0.1->pyannote.audio->-r requirements.txt (line 5)) (4.67.1)
Collecting future (from ffmpeg-python->-r requirements.txt (line 3))
  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)
Requirement already satisfied: packaging>=20.0 in ./whisper_env/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 10)) (25.0)
Requirement already satisfied: regex!=2019.12.17 in ./whisper_env/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 10)) (2025.10.23)
Requirement already satisfied: requests in ./whisper_env/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 10)) (2.32.5)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./whisper_env/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 10)) (0.22.1)
Requirement already satisfied: safetensors>=0.4.3 in ./whisper_env/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 10)) (0.6.2)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./whisper_env/lib/python3.11/site-packages (from huggingface_hub>=0.13.0->pyannote.audio->-r requirements.txt (line 5)) (1.2.0)
Requirement already satisfied: onnxruntime<2,>=1.14 in ./whisper_env/lib/python3.11/site-packages (from faster-whisper>=1.1.1->whisperx->-r requirements.txt (line 1)) (1.23.2)
Requirement already satisfied: coloredlogs in ./whisper_env/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx->-r requirements.txt (line 1)) (15.0.1)
Requirement already satisfied: flatbuffers in ./whisper_env/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx->-r requirements.txt (line 1)) (25.9.23)
Requirement already satisfied: protobuf in ./whisper_env/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx->-r requirements.txt (line 1)) (6.33.0)
Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in ./whisper_env/lib/python3.11/site-packages (from lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 5)) (0.15.2)
Requirement already satisfied: pytorch-lightning in ./whisper_env/lib/python3.11/site-packages (from lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 5)) (2.5.5)
Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./whisper_env/lib/python3.11/site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 5)) (3.13.1)
Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./whisper_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 5)) (2.6.1)
Requirement already satisfied: aiosignal>=1.4.0 in ./whisper_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 5)) (1.4.0)
Requirement already satisfied: attrs>=17.3.0 in ./whisper_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 5)) (25.4.0)
Requirement already satisfied: frozenlist>=1.1.1 in ./whisper_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 5)) (1.8.0)
Requirement already satisfied: multidict<7.0,>=4.5 in ./whisper_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 5)) (6.7.0)
Requirement already satisfied: propcache>=0.2.0 in ./whisper_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 5)) (0.4.1)
Requirement already satisfied: yarl<2.0,>=1.17.0 in ./whisper_env/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 5)) (1.22.0)
Requirement already satisfied: idna>=2.0 in ./whisper_env/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio->-r requirements.txt (line 5)) (3.11)
Requirement already satisfied: contourpy>=1.0.1 in ./whisper_env/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio->-r requirements.txt (line 5)) (1.3.3)
Requirement already satisfied: cycler>=0.10 in ./whisper_env/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio->-r requirements.txt (line 5)) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in ./whisper_env/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio->-r requirements.txt (line 5)) (4.60.1)
Requirement already satisfied: kiwisolver>=1.3.1 in ./whisper_env/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio->-r requirements.txt (line 5)) (1.4.9)
Requirement already satisfied: pyparsing>=3 in ./whisper_env/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics<4.0,>=3.2->pyannote.audio->-r requirements.txt (line 5)) (3.2.5)
Requirement already satisfied: click in ./whisper_env/lib/python3.11/site-packages (from nltk>=3.9.1->whisperx->-r requirements.txt (line 1)) (8.3.0)
Requirement already satisfied: joblib in ./whisper_env/lib/python3.11/site-packages (from nltk>=3.9.1->whisperx->-r requirements.txt (line 1)) (1.5.2)
Requirement already satisfied: alembic>=1.5.0 in ./whisper_env/lib/python3.11/site-packages (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote.audio->-r requirements.txt (line 5)) (1.17.0)
Requirement already satisfied: colorlog in ./whisper_env/lib/python3.11/site-packages (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote.audio->-r requirements.txt (line 5)) (6.10.1)
Requirement already satisfied: sqlalchemy>=1.4.2 in ./whisper_env/lib/python3.11/site-packages (from optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote.audio->-r requirements.txt (line 5)) (2.0.44)
Requirement already satisfied: Mako in ./whisper_env/lib/python3.11/site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote.audio->-r requirements.txt (line 5)) (1.3.10)
Requirement already satisfied: six>=1.5 in ./whisper_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.2.3->whisperx->-r requirements.txt (line 1)) (1.17.0)
Requirement already satisfied: markdown-it-py>=2.2.0 in ./whisper_env/lib/python3.11/site-packages (from rich>=12.0.0->pyannote.audio->-r requirements.txt (line 5)) (4.0.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./whisper_env/lib/python3.11/site-packages (from rich>=12.0.0->pyannote.audio->-r requirements.txt (line 5)) (2.19.2)
Requirement already satisfied: mdurl~=0.1 in ./whisper_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio->-r requirements.txt (line 5)) (0.1.2)
Requirement already satisfied: threadpoolctl>=3.1.0 in ./whisper_env/lib/python3.11/site-packages (from scikit-learn>=0.17.1->pyannote.metrics<4.0,>=3.2->pyannote.audio->-r requirements.txt (line 5)) (3.6.0)
Requirement already satisfied: cffi>=1.0 in ./whisper_env/lib/python3.11/site-packages (from soundfile>=0.12.1->pyannote.audio->-r requirements.txt (line 5)) (2.0.0)
Requirement already satisfied: pycparser in ./whisper_env/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio->-r requirements.txt (line 5)) (2.23)
Requirement already satisfied: hyperpyyaml in ./whisper_env/lib/python3.11/site-packages (from speechbrain>=1.0.0->pyannote.audio->-r requirements.txt (line 5)) (1.2.2)
Requirement already satisfied: sentencepiece in ./whisper_env/lib/python3.11/site-packages (from speechbrain>=1.0.0->pyannote.audio->-r requirements.txt (line 5)) (0.2.1)
Requirement already satisfied: greenlet>=1 in ./whisper_env/lib/python3.11/site-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline<4.0,>=3.0.1->pyannote.audio->-r requirements.txt (line 5)) (3.2.4)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./whisper_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 4)) (1.3.0)
Requirement already satisfied: julius<0.3,>=0.2.3 in ./whisper_env/lib/python3.11/site-packages (from torch_audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 5)) (0.2.7)
Requirement already satisfied: torch-pitch-shift>=1.2.2 in ./whisper_env/lib/python3.11/site-packages (from torch_audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 5)) (1.2.5)
Requirement already satisfied: primePy>=1.3 in ./whisper_env/lib/python3.11/site-packages (from torch-pitch-shift>=1.2.2->torch_audiomentations>=0.11.0->pyannote.audio->-r requirements.txt (line 5)) (1.3)
Requirement already satisfied: shellingham>=1.3.0 in ./whisper_env/lib/python3.11/site-packages (from typer>=0.12.1->pyannote.database<6.0,>=5.0.1->pyannote.audio->-r requirements.txt (line 5)) (1.5.4)
Requirement already satisfied: humanfriendly>=9.1 in ./whisper_env/lib/python3.11/site-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper>=1.1.1->whisperx->-r requirements.txt (line 1)) (10.0)
Requirement already satisfied: ruamel.yaml>=0.17.28 in ./whisper_env/lib/python3.11/site-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio->-r requirements.txt (line 5)) (0.18.16)
Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in ./whisper_env/lib/python3.11/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio->-r requirements.txt (line 5)) (0.2.14)
Requirement already satisfied: MarkupSafe>=2.0 in ./whisper_env/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.3)
Requirement already satisfied: charset_normalizer<4,>=2 in ./whisper_env/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 10)) (3.4.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./whisper_env/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 10)) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in ./whisper_env/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 10)) (2025.10.5)
Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)
Using cached future-1.0.0-py3-none-any.whl (491 kB)
Installing collected packages: future, ffmpeg-python

Successfully installed ffmpeg-python-0.2.0 future-1.0.0
[youtube] Extracting URL: https://www.youtube.com/watch?v=83jt-xOJok4
Downloading audio from: https://www.youtube.com/watch?v=83jt-xOJok4
[youtube] 83jt-xOJok4: Downloading webpage
[youtube] 83jt-xOJok4: Downloading android sdkless player API JSON
[youtube] 83jt-xOJok4: Downloading tv client config
[youtube] 83jt-xOJok4: Downloading tv player API JSON
[youtube] 83jt-xOJok4: Downloading web safari player API JSON
[youtube] 83jt-xOJok4: Downloading player 5cf6312f-main
[youtube] 83jt-xOJok4: Downloading m3u8 information
[info] 83jt-xOJok4: Downloading 1 format(s): 251
[download] output/Axon Body 3 Video 2022 09 15 1723 X60A0524C.webm has already been downloaded
[download] 100% of   20.08MiB

Video title: Axon Body 3 Video 2022 09 15 1723 X60A0524C
Duration: 1323 seconds

Using device: cpu
Compute type: int8
No HuggingFace token - speaker diarization will be skipped

================================================================================
Step 1: Loading WhisperX model (base) on cpu
================================================================================
2025-10-28 13:46:43 - whisperx.asr - INFO - No language specified, language will be detected for each audio file (increases inference time)
2025-10-28 13:46:43 - whisperx.vads.pyannote - INFO - Performing voice activity detection using Pyannote...
Model was trained with pyannote.audio 0.0.1, yours is 3.4.0. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.8.0+cu128. Bad things might happen unless you revert torch to 1.x.

Loading audio file: output/Axon Body 3 Video 2022 09 15 1723 X60A0524C.webm

================================================================================
Step 2: Transcribing audio
================================================================================
2025-10-28 13:47:09 - whisperx.asr - INFO - Detected language: en (0.40) in first 30s of audio

================================================================================
Step 3: Aligning transcription
================================================================================

================================================================================
WARNING: Skipping speaker diarization (no HuggingFace token provided)
================================================================================

Transcript saved to: output/transcript_20251028_134853.txt
Detailed transcript with timestamps saved to: output/transcript_20251028_134853.json
Human-readable timestamped transcript saved to: output/transcript_20251028_134853_timestamped.txt

================================================================================
TRANSCRIPT:
================================================================================
[Unknown]:  Let's go. Alright, thanks.Come in.Kurt?Good?You got a paper towel right here?Like a napkin and fuckin' sweat and the balls on. I don't know if it's going to work. I agree.We get to the side. No, no, no, no, no, no, no. If it's part of the investigation, we don't have to act.It's not for investigation.It is.You don't know what we need.It's not to happen over here.Okay, we need to make it bigger, that's what we're saying.I'm just giving you notice of the merger that this is private promise.I'm just being polite and honorable.Okay.This is private property. They're giving you notice.Okay.Okay.What I'm telling you is that if it comes down and that we need to come on it, we will.That's all I'm saying.No, you will not.That you can't do that.That's not how it works.Okay.Can we be, can we be real happy?Have I, have I, have I been disrespectful?Have I say anything?I don't know.When I say that, I'm just giving you notice that this is private property.What I'm saying?And I'm going to help and assist. But this is probably the problem.What I am telling you, nothing happened over here.I am saying.Nothing happened over here.I'm literally trying to just talk.And you just keep cutting me off.I'm just trying to have a conversation.I'm literally trying to explain something.If it necessitates, we will.That's all I'm saying.Now, a grant, I wasn't here.I don't know.I don't know what happened.All I'm saying.No one came on my land.Okay, because you said no in the table, right? So before there was a situation about it, all I was trying to say, if the situation necessitated and it became apparent and necessary, we would take the space.That's all I was saying?I didn't say anything about it.So it was okay to steal?If we just needed to block it off for whatever reason.No, you just said it was okay to take.I was making sure that the video says the same thing, you're true saying.You said it's okay to steal. Am I permanently depriving you of it?Yes, you said.You just said, take.Hasn't take this place.No, no, no.Yeah, yeah.That didn't mean stealing.So we're not doing any stealing.I'm not going to steal.I'm not going to steal.I'm not going to steal.Can I pick up a walk away with your house?That's not the point.Office of virtue?That's not the point.We're talking law.You said, take.We're not taking anything.I'm going to take it from you.You're not taking it from me.We're going to be honorable.OK, so if we want to talk law, right, you have a reasonable expectation of privacy, correct?Reasonable?No. No, I'm not part of that.No, no.Okay, let's talk about it.You want to get into a lesson today?I'm trying to be honorable.But do you understand jurisdiction?I do.That's what I'm trying to explain to you.The Fourth Amendment provides you a reasonable expectation.I'm not a U.S. citizen.First of all, that's the more.Being that you live in United States, No, I don't.You have a way in there.You have a way in there.You know that?That just happens in B and 9, which is a part of the United States, okay?Because you are in this vicinity, right?We'll say you're provided a certain exemption, right?You're provided certain protections and that's just policing or whatever it is, right?I'm not bothering you, right?You don't bother me.So all I was trying to say was, okay, you were trying, okay, go in this scenario with that. If somebody says, hey, we need to block this off because X or X and Y would happen.Yes.And I would say, hey, we don't have to act.We're just going to do it at this time.We're not going to take it forever until they're done.Then we can, we can be done with it.But all I'm saying is that as soon as the tape went up, you were just like, no, no, no, no, no, no, no.And I'm just like, hey, before we get there, if we need it, you know, that's all I was doing. You can't say you can't say I didn't say he didn't say anything You did I'll give you that I will I will consider that that you did say that now I'm not right now I'm not saying that I'm not trying to be a jerk I'm not trying to be rude obviously your property is your property I'm not gonna take anything for anybody that I don't need or I don't want or I don't have to take right all I'm saying was that if we needed to put crime scene save up across the yard for a brief moment just to check himself out if a street one happened to go somewhere what No, again, I'm just saying like hypothetically speaking, so like this is for anybody's house.You know, if a house was randomly struggling, we may have had something to do with it.If we have to take tape, obviously people don't agree with it, but obviously, I just want to at least explain understand why, right?All those I can't notice or whatever can happen illegally.Absolutely.I understand that.So, civil. What was the word you kept what was the word you can't use it?Honorable yeah Honorable yeah, okay, we're doing what you say Absolutely But this is what you want.The one that I'm pointing there.You can go.We can deduce that I couldn't out park right there.I stay literally right there.Oh, okay.Your car can make it.But you can take the stuff into the house and once the tape is down, I don't know how long it's going to be, but if you want to walk in your house.Yeah, you can walk around the tape.It's everything on the right side.It's fine.So you can get your stuff and you can come back for your car later if you want.Well, obviously you can have to. It's a good touch here. Thank you very much. You gotta get out.I'm gonna go live, we go live to take.Excuse me.I gotta get my friend for this. Merchant.Merchant.Merchant.Merchant.Merchant.Merchant. Don't put it on that first piece of there.It might not make it bad. I think, well, my camera's on, I just want to let you know.I really want to watch you play something.You did?Those guys came back and worked for quarter, quarter, quarter.Well, you never played four halves.Yeah.And then, well, three.Yeah, we never played three, but then we did.And the third, I was gassed out, man.I didn't have any more juice in the legs.What's up?They're playing here. It was a good little game.The first two halves were the best, but that third half, that third, 30 minutes, I just couldn't hang.What do you mean you had this short stuff?You had it?I know, it was all my tiptoes. Who is this?It must be us.Yeah, I'll stick it. That was awesome.That was awesome.That was brilliant. Hey, Chief.Sir, what's your name?Sorry, we carried on an entire conversation.Paid?Paid.Paid?Paid?I got an earpiece in there.I know.What were you from?Originally?Yeah, originally from New York.It's not me.Oh, really from New York?Yeah, you never heard of the ancient people who actually are the airs of this land or the bays and elves.I know you know that.Don't tell me you don't know that.You so... Because you will be really... I'd really be, I'd be not, that would be that.You'd be doing the problem, you would be doing the problem done on it, done our ability shit.Cause everybody knows about the Bayes and Elves.So everybody knows the more.So don't, historically speaking, you want to, you want a Supreme Court case to get?No, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, No, no, but that's one case that I'm gonna grab it I'm gonna tell you it is it's the heirs of Turner versus United States Heirs of Turner?The heirs of Turner.Oh heirs like the heirs.Okay.Get to the land right right versus the United States Okay, tell you right then the first first synopsis of the paragraph.We own the land.Okay.I'm not so that's all I'm saying I just wanted to share that with you so anything that you came out of that it would kind of like I'm going to write it down.See that?What's that?That's my joy.I think you, I think you, I think you BS in me, but I promise you, I'm not hairs of turner.That's the exact, but I think that's the type of angle we should come up.Versus your ass.Yeah.I will look at it.I give you my word, Mr. Bill.Yeah, no.So, no, historic.So, what were you, what were you about to say?Historicly, I am familiar with the Bays.Yes.If you guys are familiar with it.Historicly, I am familiar. Um, to say I am as knowledgeable as one like yourself is would be happy line.And my normal experience in the county within our generally sovereign citizens at work.Okay.I know.So you know, are you college educated?Yeah.Okay.You made with etymology? Not as much as one should be.Oh, but yes.So when you say sovereign citizens, it's no such thing.So you say that's why I asked you the question before I asked you the question, were you educated?I said etymology.Etymology is the root of every word.So it gives you the true meaning, not what someone wrote in a dictionary.So insane sovereign citizenship can't be sovereign. and we're part of a more science temple, Jeff Governing.I'm going to tell you what it came from.805 statues, hers revised statues in Illinois.If you look up hers revised statues in Illinois, it gives us our sovereign power just like the Vatican.So you understand that you can make the correlation in your mind.Makes sense?It does.That's all it is.That's it.It ain't no more to it than that.So we're going to confuse it. And try to make up other stuff.That's the correlation.So now you got in your mind.Okay, it's just like I've been looking at one of the pope's ministers.Yes, that's who I am.That's the correlation to keep it simple in your mind so you don't have to think of something. or use the word you just use, which is actually disrespectful number one, it is.But you didn't know.Now, you know.Right.Well, you even still, I'm gonna say, I'll apologize.Never be sorry.Never be sorry.Sorry to stay to be in.Right.Now, you put your knoll now.You're educated.Absolutely.So that's it.You can knock him.Okay.Now, so you can, in your mind, you got, okay, this ain't no.He just, he just, he just, he just, right?Which he has rights to.Everyone has rights.Absolutely.And it's been acknowledged by all the people that know, rather than all down.Everyone knows our status. Right.They know it.So it's on the record with the Ike Knight on the Supreme Court but with the Federal Court.And in the county.Right.From my name, it gives you who I am.Commercially, and as a man on the land.Both. I'm just trying to educate you not being this so you won't be English like most of you don't mention the time on him But now you now you get in your mind.Okay.I got it.I see what he's saying It's simple, so but most of them don't know that or some know and still try to be What do you call it?No, no, no, no, not honorable.Oh, the key word Just keep it honorable, like that word.Yes, but it's fitting.What we did with two governments and they're substituted.You were substituted, right, of the US government.Yes, correct.So, that's all, that's all what it is.Now, what these young, well, what they were doing, I don't know what happened.I was going to back in my house on this car when I heard shots fired.Something less than pleasurable, we'll say, like that.And which brings me back to the original point of, Because of what it is, there's no telling what they might ask of people nearby.So I understand.I'll explain it like this.Let's say if I'm running after somebody and I lose sight of them, you want to start a circle as big as you can and collapse it as you can come in.So I don't know where everything's because I wasn't even here.I don't know where everything was when it happened.Normally, we'll always go bigger as a failsafe and then once we know exactly what honing in. But the conversation that you and I had is the one that we have a lot of times because some people are just like hey, you know, just my property you can't be here And as respectfully as we have to explain is that hey, I understand that where I'm not here for forever.I'm not here to do I know what you was right and I want to I really want to have some education That's what I really want to know I appreciate that's my whole goal never to go to learn If you shouldn't be don't be unintelligent to have a vehicle ever bought to subscribe.There's no channel nine Hey Mr. Bay, should I see you again?Absolutely.Absolutely.I appreciate that conversation. You almost got it.It's time to come to cream.I was kind of surprised. I don't see.I don't see.Sorry, do we have people watching?Yes, sir.I'll sit on the side with him if he needs to. Oh, yeah.[youtube] Extracting URL: https://www.youtube.com/watch?v=83jt-xOJok4

================================================================================

================================================================================
TRANSCRIPTION COMPLETE!
================================================================================
Audio file: output/Axon Body 3 Video 2022 09 15 1723 X60A0524C.webm
Transcript: output/transcript_20251028_134853.txt
Timestamped transcript: output/transcript_20251028_134853_timestamped.txt
Detailed output: output/transcript_20251028_134853.json

================================================================================
STARTING VIDEO PROCESSING
================================================================================
Downloading video from: https://www.youtube.com/watch?v=83jt-xOJok4
[youtube] 83jt-xOJok4: Downloading webpage
[youtube] 83jt-xOJok4: Downloading android sdkless player API JSON
[youtube] 83jt-xOJok4: Downloading tv client config
[youtube] 83jt-xOJok4: Downloading tv player API JSON
[youtube] 83jt-xOJok4: Downloading web safari player API JSON
[youtube] 83jt-xOJok4: Downloading player 5cf6312f-main
[youtube] 83jt-xOJok4: Downloading m3u8 information
[info] 83jt-xOJok4: Downloading 1 format(s): 137+140
[download] output/Axon Body 3 Video 2022 09 15 1723 X60A0524C.mp4 has already been downloaded
Video downloaded: output/Axon Body 3 Video 2022 09 15 1723 X60A0524C.mp4

Video processing parameters:
  Chunk duration: 5.0s
  Frames per chunk: 5
  CLIP model: openai/clip-vit-base-patch32

================================================================================
PROCESSING VIDEO WITH CLIP EMBEDDINGS
================================================================================

Loading CLIP model: openai/clip-vit-base-patch32 on cpu
CLIP model loaded successfully!

Video: output/Axon Body 3 Video 2022 09 15 1723 X60A0524C.mp4
Duration: 1322.73s, FPS: 30.00, Frames: 39682

================================================================================
Creating video chunks with duration: 5.0s
Video duration: 1322.73s
================================================================================
Created 265 chunks

================================================================================
EXTRACTING FRAMES AND EMBEDDINGS
================================================================================

Processing chunk 1/265: 0.00s - 5.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 2/265: 5.00s - 10.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 3/265: 10.00s - 15.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 4/265: 15.00s - 20.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 5/265: 20.00s - 25.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 6/265: 25.00s - 30.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 7/265: 30.00s - 35.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 8/265: 35.00s - 40.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 9/265: 40.00s - 45.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 10/265: 45.00s - 50.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 11/265: 50.00s - 55.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 12/265: 55.00s - 60.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 13/265: 60.00s - 65.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 14/265: 65.00s - 70.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 15/265: 70.00s - 75.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 16/265: 75.00s - 80.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 17/265: 80.00s - 85.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 18/265: 85.00s - 90.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 19/265: 90.00s - 95.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 20/265: 95.00s - 100.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 21/265: 100.00s - 105.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 22/265: 105.00s - 110.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 23/265: 110.00s - 115.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 24/265: 115.00s - 120.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 25/265: 120.00s - 125.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 26/265: 125.00s - 130.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 27/265: 130.00s - 135.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 28/265: 135.00s - 140.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 29/265: 140.00s - 145.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 30/265: 145.00s - 150.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 31/265: 150.00s - 155.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 32/265: 155.00s - 160.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 33/265: 160.00s - 165.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 34/265: 165.00s - 170.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 35/265: 170.00s - 175.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 36/265: 175.00s - 180.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 37/265: 180.00s - 185.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 38/265: 185.00s - 190.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 39/265: 190.00s - 195.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 40/265: 195.00s - 200.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 41/265: 200.00s - 205.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 42/265: 205.00s - 210.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 43/265: 210.00s - 215.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 44/265: 215.00s - 220.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 45/265: 220.00s - 225.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 46/265: 225.00s - 230.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 47/265: 230.00s - 235.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 48/265: 235.00s - 240.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 49/265: 240.00s - 245.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 50/265: 245.00s - 250.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 51/265: 250.00s - 255.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 52/265: 255.00s - 260.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 53/265: 260.00s - 265.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 54/265: 265.00s - 270.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 55/265: 270.00s - 275.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 56/265: 275.00s - 280.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 57/265: 280.00s - 285.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 58/265: 285.00s - 290.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 59/265: 290.00s - 295.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 60/265: 295.00s - 300.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 61/265: 300.00s - 305.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 62/265: 305.00s - 310.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 63/265: 310.00s - 315.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 64/265: 315.00s - 320.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 65/265: 320.00s - 325.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 66/265: 325.00s - 330.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 67/265: 330.00s - 335.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 68/265: 335.00s - 340.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 69/265: 340.00s - 345.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 70/265: 345.00s - 350.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 71/265: 350.00s - 355.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 72/265: 355.00s - 360.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 73/265: 360.00s - 365.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 74/265: 365.00s - 370.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 75/265: 370.00s - 375.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 76/265: 375.00s - 380.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 77/265: 380.00s - 385.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 78/265: 385.00s - 390.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 79/265: 390.00s - 395.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 80/265: 395.00s - 400.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 81/265: 400.00s - 405.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 82/265: 405.00s - 410.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 83/265: 410.00s - 415.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 84/265: 415.00s - 420.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 85/265: 420.00s - 425.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 86/265: 425.00s - 430.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 87/265: 430.00s - 435.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 88/265: 435.00s - 440.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 89/265: 440.00s - 445.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 90/265: 445.00s - 450.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 91/265: 450.00s - 455.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 92/265: 455.00s - 460.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 93/265: 460.00s - 465.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 94/265: 465.00s - 470.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 95/265: 470.00s - 475.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 96/265: 475.00s - 480.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 97/265: 480.00s - 485.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 98/265: 485.00s - 490.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 99/265: 490.00s - 495.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 100/265: 495.00s - 500.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 101/265: 500.00s - 505.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 102/265: 505.00s - 510.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 103/265: 510.00s - 515.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 104/265: 515.00s - 520.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 105/265: 520.00s - 525.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 106/265: 525.00s - 530.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 107/265: 530.00s - 535.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 108/265: 535.00s - 540.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 109/265: 540.00s - 545.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 110/265: 545.00s - 550.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 111/265: 550.00s - 555.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 112/265: 555.00s - 560.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 113/265: 560.00s - 565.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 114/265: 565.00s - 570.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 115/265: 570.00s - 575.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 116/265: 575.00s - 580.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 117/265: 580.00s - 585.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 118/265: 585.00s - 590.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 119/265: 590.00s - 595.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 120/265: 595.00s - 600.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 121/265: 600.00s - 605.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 122/265: 605.00s - 610.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 123/265: 610.00s - 615.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 124/265: 615.00s - 620.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 125/265: 620.00s - 625.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 126/265: 625.00s - 630.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 127/265: 630.00s - 635.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 128/265: 635.00s - 640.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 129/265: 640.00s - 645.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 130/265: 645.00s - 650.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 131/265: 650.00s - 655.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 132/265: 655.00s - 660.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 133/265: 660.00s - 665.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 134/265: 665.00s - 670.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 135/265: 670.00s - 675.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 136/265: 675.00s - 680.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 137/265: 680.00s - 685.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 138/265: 685.00s - 690.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 139/265: 690.00s - 695.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 140/265: 695.00s - 700.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 141/265: 700.00s - 705.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 142/265: 705.00s - 710.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 143/265: 710.00s - 715.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 144/265: 715.00s - 720.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 145/265: 720.00s - 725.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 146/265: 725.00s - 730.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 147/265: 730.00s - 735.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 148/265: 735.00s - 740.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 149/265: 740.00s - 745.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 150/265: 745.00s - 750.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 151/265: 750.00s - 755.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 152/265: 755.00s - 760.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 153/265: 760.00s - 765.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 154/265: 765.00s - 770.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 155/265: 770.00s - 775.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 156/265: 775.00s - 780.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 157/265: 780.00s - 785.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 158/265: 785.00s - 790.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 159/265: 790.00s - 795.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 160/265: 795.00s - 800.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 161/265: 800.00s - 805.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 162/265: 805.00s - 810.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 163/265: 810.00s - 815.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 164/265: 815.00s - 820.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 165/265: 820.00s - 825.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 166/265: 825.00s - 830.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 167/265: 830.00s - 835.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 168/265: 835.00s - 840.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 169/265: 840.00s - 845.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 170/265: 845.00s - 850.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 171/265: 850.00s - 855.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 172/265: 855.00s - 860.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 173/265: 860.00s - 865.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 174/265: 865.00s - 870.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 175/265: 870.00s - 875.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 176/265: 875.00s - 880.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 177/265: 880.00s - 885.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 178/265: 885.00s - 890.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 179/265: 890.00s - 895.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 180/265: 895.00s - 900.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 181/265: 900.00s - 905.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 182/265: 905.00s - 910.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 183/265: 910.00s - 915.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 184/265: 915.00s - 920.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 185/265: 920.00s - 925.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 186/265: 925.00s - 930.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 187/265: 930.00s - 935.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 188/265: 935.00s - 940.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 189/265: 940.00s - 945.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 190/265: 945.00s - 950.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 191/265: 950.00s - 955.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 192/265: 955.00s - 960.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 193/265: 960.00s - 965.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 194/265: 965.00s - 970.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 195/265: 970.00s - 975.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 196/265: 975.00s - 980.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 197/265: 980.00s - 985.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 198/265: 985.00s - 990.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 199/265: 990.00s - 995.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 200/265: 995.00s - 1000.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 201/265: 1000.00s - 1005.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 202/265: 1005.00s - 1010.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 203/265: 1010.00s - 1015.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 204/265: 1015.00s - 1020.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 205/265: 1020.00s - 1025.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 206/265: 1025.00s - 1030.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 207/265: 1030.00s - 1035.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 208/265: 1035.00s - 1040.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 209/265: 1040.00s - 1045.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 210/265: 1045.00s - 1050.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 211/265: 1050.00s - 1055.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 212/265: 1055.00s - 1060.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 213/265: 1060.00s - 1065.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 214/265: 1065.00s - 1070.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 215/265: 1070.00s - 1075.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 216/265: 1075.00s - 1080.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 217/265: 1080.00s - 1085.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 218/265: 1085.00s - 1090.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 219/265: 1090.00s - 1095.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 220/265: 1095.00s - 1100.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 221/265: 1100.00s - 1105.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 222/265: 1105.00s - 1110.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 223/265: 1110.00s - 1115.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 224/265: 1115.00s - 1120.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 225/265: 1120.00s - 1125.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 226/265: 1125.00s - 1130.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 227/265: 1130.00s - 1135.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 228/265: 1135.00s - 1140.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 229/265: 1140.00s - 1145.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 230/265: 1145.00s - 1150.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 231/265: 1150.00s - 1155.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 232/265: 1155.00s - 1160.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 233/265: 1160.00s - 1165.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 234/265: 1165.00s - 1170.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 235/265: 1170.00s - 1175.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 236/265: 1175.00s - 1180.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 237/265: 1180.00s - 1185.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 238/265: 1185.00s - 1190.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 239/265: 1190.00s - 1195.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 240/265: 1195.00s - 1200.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 241/265: 1200.00s - 1205.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 242/265: 1205.00s - 1210.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 243/265: 1210.00s - 1215.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 244/265: 1215.00s - 1220.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 245/265: 1220.00s - 1225.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 246/265: 1225.00s - 1230.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 247/265: 1230.00s - 1235.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 248/265: 1235.00s - 1240.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 249/265: 1240.00s - 1245.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 250/265: 1245.00s - 1250.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 251/265: 1250.00s - 1255.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 252/265: 1255.00s - 1260.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 253/265: 1260.00s - 1265.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 254/265: 1265.00s - 1270.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 255/265: 1270.00s - 1275.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 256/265: 1275.00s - 1280.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 257/265: 1280.00s - 1285.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 258/265: 1285.00s - 1290.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 259/265: 1290.00s - 1295.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 260/265: 1295.00s - 1300.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 261/265: 1300.00s - 1305.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 262/265: 1305.00s - 1310.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 263/265: 1310.00s - 1315.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 264/265: 1315.00s - 1320.00s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)
Processing chunk 265/265: 1320.00s - 1322.73s
  Extracted 5 frames
  Extracted embeddings: shape (5, 512)

================================================================================
VIDEO PROCESSING COMPLETE
================================================================================
Total chunks: 265
Total frames: 1325
Total embeddings shape: (1325, 512)

================================================================================
SAVED OUTPUT FILES
================================================================================
Metadata (JSON): output/video_embeddings_20251028_135243.json
Embeddings (numpy): output/video_embeddings_20251028_135243_embeddings.npy
Complete data (pickle): output/video_embeddings_20251028_135243_complete.pkl

================================================================================
SUMMARY STATISTICS
================================================================================
Total chunks: 265
Total frames: 1325
Embedding shape: (1325, 512)
Embedding dimension: 512

================================================================================
EXAMPLE CHUNKS (first 3)
================================================================================

Chunk 0:
  Time: 0.00s - 5.00s
  Frames: 5
  Transcript segments: 0

Chunk 1:
  Time: 5.00s - 10.00s
  Frames: 5
  Transcript segments: 0

Chunk 2:
  Time: 10.00s - 15.00s
  Frames: 5
  Transcript segments: 0

================================================================================
ALL PROCESSING COMPLETE!
================================================================================

Generated files:
  - Transcript (text): output/transcript_20251028_134853.txt
  - Transcript (timestamped): output/transcript_20251028_134853_timestamped.txt
  - Transcript (JSON): output/transcript_20251028_134853.json
  - Video embeddings (JSON, .npy, .pkl) in output/

The dataset is ready for semantic search and QA tasks!
Transcription completed!
